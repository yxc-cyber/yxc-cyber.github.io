---
title: Goal Alignment in LLM-Based User Simulators for Conversational AI
authors:
- Shuhaib Mehri
- Xiaocheng Yang
- Takyoung Kim
- Gokhan Tur
- Shikib Mehri
- Dilek Hakkani-TÃ¼r
date: '2025-07-27'
publishDate: '2025-08-02T03:00:21.164250Z'
publication_types:
- manuscript
links:
- name: arXiv
  url: https://arxiv.org/abs/2507.20152
- name: URL
  url: https://arxiv.org/abs/2507.20152
image:
  caption: "The goal-aligned user simulator response (right) considers their goal progression, and reasons to generate a response that maintains alignment with the user goal."
  focal_point: ''
  preview_only: false
featured: true
---
